# -*- coding: utf-8 -*-
"""Lyra_Oidium_7B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xwfZZfUi2ukX_0Lq4asWDgD0rRsnONoX
"""

# Bloc 1 â€” Install & vÃ©rification des fichiers JSONL
!pip install -q --upgrade "transformers>=4.46.0" peft datasets trl accelerate huggingface_hub

import transformers
import trl
import torch

print("transformers version :", transformers.__version__)
print("trl version          :", trl.__version__)
print("torch version        :", torch.__version__)
print("CUDA dispo:", torch.cuda.is_available())

import os, json

# ğŸ”§ chemins vers les datasets
train_path = "/content/sample_data/Oidium_Mistral7B_train_1500.jsonl"
valid_path = "/content/sample_data/Oidium_Mistral7B_eval_100.jsonl"  # petit jeu d'Ã©val manuel

def check_jsonl(path, n=3):
    print(f"\nğŸ” VÃ©rification du fichier : {path}")
    if not os.path.exists(path):
        print("âŒ Fichier introuvable.")
        return False
    try:
        with open(path, "r", encoding="utf-8") as f:
            lines = [next(f).strip() for _ in range(n)]
        print(f"âœ… Fichier trouvÃ© ({os.path.getsize(path)/1024:.1f} Ko)")
        for i, line in enumerate(lines, 1):
            data = json.loads(line)
            print(f"â€” Ligne {i} OK, clÃ©s principales :", list(data.keys()))
        print("âœ… Structure JSONL valide (au moins sur les 3 premiÃ¨res lignes).")
        return True
    except Exception as e:
        print("âš ï¸ Erreur :", e)
        return False

ok_train = check_jsonl(train_path)
ok_valid = check_jsonl(valid_path)

if ok_train and ok_valid:
    print("\nğŸš€ Les deux datasets sont valides et prÃªts Ã  Ãªtre chargÃ©s.")
else:
    print("\nâš ï¸ ProblÃ¨me dÃ©tectÃ© sur au moins un des fichiers.")

# Bloc 2 â€” Login Hugging Face avec TOKEN_HF_Oidium
import torch, os
from google.colab import userdata
from huggingface_hub import login

base_model_id = "mistralai/Mistral-7B-Instruct-v0.3"

print("GPU :", torch.cuda.get_device_name(0))
print("CUDA dispo:", torch.cuda.is_available())

# ğŸ” secret Colab doit s'appeler TOKEN_HF_Oidium
hf_token = userdata.get('TOKEN_HF_Oidium')
if not hf_token:
    raise ValueError("âŒ Le secret TOKEN_HF_Oidium est introuvable ou vide.")
os.environ["HF_TOKEN"] = hf_token

login(token=os.environ["HF_TOKEN"])
print("ğŸ” Connexion Hugging Face OK")

# Bloc 3 â€” Chargement du JSONL & application chat template avec prompt systÃ¨me

import json
from datasets import Dataset, DatasetDict
from transformers import AutoTokenizer

def load_jsonl(path):
    rows = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            rows.append(json.loads(line))
    return rows

train_rows = load_jsonl(train_path)
valid_rows = load_jsonl(valid_path)

dataset = DatasetDict({
    "train": Dataset.from_list(train_rows),
    "validation": Dataset.from_list(valid_rows)
})

print("taille train :", len(dataset["train"]))
print("taille valid :", len(dataset["validation"]))
print("exemple brut :", dataset["train"][0])

tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"

SYSTEM_PROMPT = """Tu es un expert agronome spÃ©cialisÃ© dans la prÃ©diction du risque d'oÃ¯dium de la vigne (*Erysiphe necator*).
Ton rÃ´le est d'Ã©valuer le risque d'infection Ã  partir des paramÃ¨tres suivants, puis de fournir une recommandation agronomique concise et actionnable.

### ParamÃ¨tres d'entrÃ©e (Ã  fournir dans chaque requÃªte) :
1. **Stade_phenologique** : "jeunes_feuilles", "floraison", ou "autre".
2. **HumiditÃ©_relative** : Valeur en % (50â€“95). Seuil critique : â‰¥70â€“80% pendant â‰¥6h.
3. **TempÃ©rature_moyenne** : Valeur en Â°C (10â€“35). Optimum : 20â€“25Â°C. Limites : <12Â°C ou >30Â°C = risque faible.
4. **Pluie_24h** : BoolÃ©en (0 ou 1). Indique une pluie dans les derniÃ¨res 24h.
5. **Inoculum** : Valeur de 0 Ã  1. Proxy basÃ© sur les infections des 2 derniÃ¨res annÃ©es.
6. **ETP** : Ã‰vapotranspiration potentielle en mm/jour (2â€“6). â‰¥4 mm/j = assÃ¨chement fort (rÃ©duction du risque si pluie rÃ©cente).

### RÃ¨gles pour l'Ã©valuation du risque :
- **Risque Ã©levÃ©** :
  - **HumiditÃ©_relative â‰¥ 80%** ET **TempÃ©rature_moyenne entre 20â€“25Â°C** ET **Stade_phenologique = "jeunes_feuilles" ou "floraison"** ET **Inoculum â‰¥ 0.5**.
  - Si **Pluie_24h = 1** ET **ETP < 4**, le risque reste Ã©levÃ© (microclimat humide persistant).
- **Risque moyen** :
  - **HumiditÃ©_relative entre 70â€“80%** ET **TempÃ©rature_moyenne entre 15â€“30Â°C** (hors optimum) ET **Inoculum entre 0.3â€“0.7**.
  - Si **Pluie_24h = 1** ET **ETP â‰¥ 4**, le risque peut Ãªtre rÃ©duit Ã  moyen (effet rinÃ§ant de lâ€™ETP).
- **Risque faible** :
  - **HumiditÃ©_relative < 70%** OU **TempÃ©rature_moyenne < 12Â°C ou > 30Â°C** OU **Inoculum < 0.3**.
  - **Pluie_24h = 1** ET **ETP â‰¥ 4** confirme un risque faible (assÃ¨chement rapide).

### Sortie attendue :
RÃ©ponds **uniquement** avec le format suivant :

Risque : [faible/moyen/Ã©levÃ©]
Recommandation : [1 Ã  3 phrases max, prÃ©cises et actionnables]


### Exemples de recommandations :
- **Risque faible** : "Aucune action requise. Conditions dÃ©favorables Ã  lâ€™infection par lâ€™oÃ¯dium."
- **Risque moyen** : "Surveiller les jeunes feuilles. Appliquer un traitement prÃ©ventif Ã  base de soufre si lâ€™humiditÃ© relative nocturne dÃ©passe 80% pendant plus de 6 heures."
- **Risque Ã©levÃ©** : "Traiter immÃ©diatement avec un fongicide systÃ©mique ou du soufre. Cibler les inflorescences et renouveler le traitement aprÃ¨s 7 Ã  10 jours si les conditions favorables persistent."

### Consignes strictes :
- Ne pas inclure d'explications ou de justifications supplÃ©mentaires.
- Respecter strictement le format de sortie.
- Utiliser des termes techniques prÃ©cis (ex : "soufre", "fongicide systÃ©mique").
- Adapter les recommandations au **Stade_phenologique** (ex : cibler les inflorescences en floraison).

"""

def to_chat_text(example):
    # On suppose que example["messages"] contient dÃ©jÃ  user + assistant,
    # sans message systÃ¨me. On le prÃ©fixe par le SYSTEM_PROMPT.
    chat_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + example["messages"]
    txt = tokenizer.apply_chat_template(
        chat_messages,
        tokenize=False,
        add_generation_prompt=False,
    )
    return {"text": txt}

dataset = dataset.map(to_chat_text)

print("aperÃ§u text :", dataset["train"][0]["text"][:500])

print("transformers version :", transformers.__version__)
print("trl version          :", trl.__version__)
print("torch version        :", torch.__version__)
print("CUDA dispo:", torch.cuda.is_available())

# Bloc 4 â€” Chargement du modÃ¨le de base & configuration LoRA

from transformers import AutoModelForCausalLM
from peft import LoraConfig, get_peft_model
import torch

base_model_id = "mistralai/Mistral-7B-Instruct-v0.3"

model = AutoModelForCausalLM.from_pretrained(
    base_model_id,
    torch_dtype=torch.float16,
    device_map="auto",   # accelerate rÃ©partit sur le GPU (et CPU si besoin)
)

lora_config = LoraConfig(
    r=64,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=[
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj",
    ],
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# Bloc 5 â€” SFTTrainer + hyperparamÃ¨tres Oidium
from trl import SFTTrainer
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./lyra_Oidium_LoRA",   # dossier de travail (checkpoints intermÃ©diaires)
    num_train_epochs=3,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    gradient_accumulation_steps=8,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    eval_strategy="epoch",
    save_strategy="epoch",
    lr_scheduler_type="cosine",
    warmup_ratio=0.03,
    weight_decay=0.0,
    report_to="none",
)

trainer = SFTTrainer(
    model=model,
    processing_class=tokenizer,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    args=training_args,
)

trainer.train()

# Bloc 6 â€” Sauvegarde des adapters dans ./lyra_Oidium_adapter

output_dir = "./lyra_Oidium_adapter"

trainer.model.save_pretrained(output_dir)
tokenizer.save_pretrained(output_dir)

print("Adapters sauvegardÃ©s dans", output_dir)
!ls -R {output_dir}

### ğŸ“¤ Bloc 7 â€” Push du modÃ¨le sur Hugging Face


from huggingface_hub import create_repo

# â¬‡ï¸ username HF
hf_repo_id = "jeromex1/lyra_Oidium_mistral7B_LoRA"

print("Repo cible :", hf_repo_id)

# CrÃ©e le repo si besoin
create_repo(hf_repo_id, exist_ok=True)

# Push du modÃ¨le (adapters PEFT) et du tokenizer
trainer.model.push_to_hub(hf_repo_id)
tokenizer.push_to_hub(hf_repo_id)

print(f"âœ… ModÃ¨le et tokenizer poussÃ©s sur : https://huggingface.co/{hf_repo_id}")

###########################################
# cellule ci dessous Ã  modifier si besoin #
###########################################

# Bloc 8 â€” InfÃ©rences de test sur quelques situations Oidium
import torch
model.eval()

# Prompt systÃ¨me pour l'Oidium (dÃ©jÃ  dÃ©fini)
SYSTEM_PROMPT = """
Tu es un expert agronome spÃ©cialisÃ© dans la prÃ©diction du risque d'oÃ¯dium de la vigne (*Erysiphe necator*).
Ton rÃ´le est d'Ã©valuer le risque d'infection Ã  partir des paramÃ¨tres suivants, puis de fournir une recommandation agronomique concise et actionnable.

### ParamÃ¨tres d'entrÃ©e (Ã  fournir dans chaque requÃªte) :
1. **Stade_phenologique** : "jeunes_feuilles", "floraison", ou "autre".
2. **HumiditÃ©_relative** : Valeur en % (50â€“95). Seuil critique : â‰¥70â€“80% pendant â‰¥6h.
3. **TempÃ©rature_moyenne** : Valeur en Â°C (10â€“35). Optimum : 20â€“25Â°C. Limites : <12Â°C ou >30Â°C = risque faible.
4. **Pluie_24h** : BoolÃ©en (0 ou 1). Indique une pluie dans les derniÃ¨res 24h.
5. **Inoculum** : Valeur de 0 Ã  1. Proxy basÃ© sur les infections des 2 derniÃ¨res annÃ©es.
6. **ETP** : Ã‰vapotranspiration potentielle en mm/jour (2â€“6). â‰¥4 mm/j = assÃ¨chement fort (rÃ©duction du risque si pluie rÃ©cente).

### RÃ¨gles pour l'Ã©valuation du risque :
- **Risque Ã©levÃ©** :
  - **HumiditÃ©_relative â‰¥ 80%** ET **TempÃ©rature_moyenne entre 20â€“25Â°C** ET **Stade_phenologique = "jeunes_feuilles" ou "floraison"** ET **Inoculum â‰¥ 0.5**.
  - Si **Pluie_24h = 1** ET **ETP < 4**, le risque reste Ã©levÃ© (microclimat humide persistant).
- **Risque moyen** :
  - **HumiditÃ©_relative entre 70â€“80%** ET **TempÃ©rature_moyenne entre 15â€“30Â°C** (hors optimum) ET **Inoculum entre 0.3â€“0.7**.
  - Si **Pluie_24h = 1** ET **ETP â‰¥ 4**, le risque peut Ãªtre rÃ©duit Ã  moyen (effet rinÃ§ant de lâ€™ETP).
- **Risque faible** :
  - **HumiditÃ©_relative < 70%** OU **TempÃ©rature_moyenne < 12Â°C ou > 30Â°C** OU **Inoculum < 0.3**.
  - **Pluie_24h = 1** ET **ETP â‰¥ 4** confirme un risque faible (assÃ¨chement rapide).

### Sortie attendue :
RÃ©ponds **uniquement** avec le format suivant :
Risque : [faible/moyen/Ã©levÃ©]
Recommandation : [1 Ã  3 phrases max, prÃ©cises et actionnables]

### Exemples de recommandations :
- **Risque faible** : "Aucune action requise. Conditions dÃ©favorables Ã  lâ€™infection par lâ€™oÃ¯dium."
- **Risque moyen** : "Surveiller les jeunes feuilles. Appliquer un traitement prÃ©ventif Ã  base de soufre si lâ€™humiditÃ© relative nocturne dÃ©passe 80% pendant plus de 6 heures."
- **Risque Ã©levÃ©** : "Traiter immÃ©diatement avec un fongicide systÃ©mique ou du soufre. Cibler les inflorescences et renouveler le traitement aprÃ¨s 7 Ã  10 jours si les conditions favorables persistent."

### Consignes strictes :
- Ne pas inclure d'explications ou de justifications supplÃ©mentaires.
- Respecter strictement le format de sortie.
- Utiliser des termes techniques prÃ©cis (ex : "soufre", "fongicide systÃ©mique").
- Adapter les recommandations au **Stade_phenologique** (ex : cibler les inflorescences en floraison).
"""

def format_user(stade, humidite_relative, temperature, pluie, inoculum, etp):
    return (
        f"Stade_phenologique: {stade}\n"
        f"HumiditÃ©_relative: {humidite_relative}\n"
        f"TempÃ©rature_moyenne: {temperature}\n"
        f"Pluie_24h: {pluie}\n"
        f"Inoculum: {inoculum}\n"
        f"ETP: {etp}\n\n"
        "Ã‰value le risque d'oÃ¯dium et propose une recommandation agronomique."
    )

def infer_case(stade, humidite_relative, temperature, pluie, inoculum, etp, label=""):
    user_content = format_user(stade, humidite_relative, temperature, pluie, inoculum, etp)
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_content},
    ]
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
    )
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=200,
            do_sample=False,  # Sortie stable et reproductible
        )
    # DÃ©codage de la rÃ©ponse (sans le prompt)
    generated = tokenizer.decode(
        outputs[0][inputs["input_ids"].shape[1]:],
        skip_special_tokens=True,
    ).strip()
    print("=" * 80)
    if label:
        print(f"ğŸ§ª Cas de test : {label}")
    print("Input :")
    print(user_content)
    print("\nRÃ©ponse du modÃ¨le :")
    print(generated)
    print()

# --- Cas de test : Risque FAIBLE ---
# Cas 1 : Conditions dÃ©favorables (tempÃ©rature Ã©levÃ©e, pas de pluie)
infer_case(
    stade="autre",
    humidite_relative=60,
    temperature=28,
    pluie=0,
    inoculum=0.2,
    etp=5,
    label="Faible 1 â€” TempÃ©rature trop Ã©levÃ©e, pas de pluie, inoculum faible",
)

# Cas 2 : HumiditÃ© relative insuffisante
infer_case(
    stade="jeunes_feuilles",
    humidite_relative=65,
    temperature=22,
    pluie=0,
    inoculum=0.3,
    etp=4,
    label="Faible 2 â€” HumiditÃ© relative <70%, inoculum faible",
)

# Cas 3 : TempÃ©rature hors optimum
infer_case(
    stade="autre",
    humidite_relative=70,
    temperature=10,
    pluie=0,
    inoculum=0.2,
    etp=3,
    label="Faible 3 â€” TempÃ©rature trop basse, humiditÃ© relative limite",
)

# Cas 4 : ETP Ã©levÃ©e aprÃ¨s pluie
infer_case(
    stade="autre",
    humidite_relative=75,
    temperature=20,
    pluie=1,
    inoculum=0.4,
    etp=5,
    label="Faible 4 â€” ETP Ã©levÃ©e aprÃ¨s pluie, humiditÃ© relative modÃ©rÃ©e",
)

# --- Cas de test : Risque MOYEN ---
# Cas 5 : HumiditÃ© relative et tempÃ©rature modÃ©rÃ©es
infer_case(
    stade="jeunes_feuilles",
    humidite_relative=75,
    temperature=22,
    pluie=0,
    inoculum=0.5,
    etp=3,
    label="Moyen 1 â€” HumiditÃ© relative et tempÃ©rature modÃ©rÃ©es, inoculum moyen",
)

# Cas 6 : Floraison avec humiditÃ© relative modÃ©rÃ©e
infer_case(
    stade="floraison",
    humidite_relative=78,
    temperature=21,
    pluie=0,
    inoculum=0.4,
    etp=3,
    label="Moyen 2 â€” Floraison avec humiditÃ© relative modÃ©rÃ©e, inoculum faible",
)

# Cas 7 : HumiditÃ© relative Ã©levÃ©e mais ETP Ã©levÃ©e
infer_case(
    stade="jeunes_feuilles",
    humidite_relative=80,
    temperature=23,
    pluie=1,
    inoculum=0.6,
    etp=5,
    label="Moyen 3 â€” HumiditÃ© relative Ã©levÃ©e mais ETP Ã©levÃ©e aprÃ¨s pluie",
)

# Cas 8 : Inoculum moyen et conditions limites
infer_case(
    stade="autre",
    humidite_relative=75,
    temperature=18,
    pluie=0,
    inoculum=0.5,
    etp=2,
    label="Moyen 4 â€” Inoculum moyen et conditions limites",
)

# --- Cas de test : Risque Ã‰LEVÃ‰ ---
# Cas 9 : Conditions optimales pour l'oÃ¯dium
infer_case(
    stade="floraison",
    humidite_relative=85,
    temperature=22,
    pluie=0,
    inoculum=0.8,
    etp=2,
    label="Ã‰levÃ© 1 â€” Conditions optimales pour l'oÃ¯dium, floraison",
)

# Cas 10 : HumiditÃ© relative et inoculum Ã©levÃ©s
infer_case(
    stade="jeunes_feuilles",
    humidite_relative=85,
    temperature=23,
    pluie=0,
    inoculum=0.8,
    etp=2,
    label="Ã‰levÃ© 2 â€” HumiditÃ© relative et inoculum Ã©levÃ©s, jeunes feuilles",
)

# Cas 11 : Pluie rÃ©cente et humiditÃ© relative Ã©levÃ©e
infer_case(
    stade="floraison",
    humidite_relative=85,
    temperature=22,
    pluie=1,
    inoculum=0.7,
    etp=2,
    label="Ã‰levÃ© 3 â€” Pluie rÃ©cente et humiditÃ© relative Ã©levÃ©e, floraison",
)

# Cas 12 : Tous les facteurs dÃ©favorables
infer_case(
    stade="floraison",
    humidite_relative=90,
    temperature=23,
    pluie=1,
    inoculum=0.9,
    etp=2,
    label="Ã‰levÃ© 4 â€” Tous les facteurs dÃ©favorables, floraison",
)

